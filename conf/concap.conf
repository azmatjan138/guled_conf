# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.
input {
file {
      path => "/home/demo/concap.csv"
      start_position => "beginning"
	  sincedb_path => "/dev/null"
    }
}

filter {	
	csv{
	separator => ","
	columns => ["CountryName","CapitalName","CapitalLatitude","CapitalLongitude","CountryCode","ContinentName"]
#	remove_field => ["host", "@timestamp", "@version", "message","path"]
	}
#
	mutate {
        add_field => ["[location]", "%{CapitalLongitude}"]
        add_field => ["[location]", "%{CapitalLatitude}"]
	}
	 
	mutate{
	convert  => ["[location]","float"]
	 		}
	  
}

output {
  elasticsearch {
    hosts => ["http://es.guled.net:9202"]
    index => "concap"
    template => "/home/demo/conf/csv.json"
    template_name => "cap"
    template_overwrite => true
    user => "elastic"
    password => "guled1113"
  }

stdout{}

}
