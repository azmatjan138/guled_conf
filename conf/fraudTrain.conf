# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
file {
      path => "/home/demo/fraudTrain.csv"
      start_position => "beginning"
	  sincedb_path => "/dev/null"
    }
}

filter {	
	csv{
	separator => ","
	columns => ["num","trans_date_trans_time","cc_num","merchant","category","amt","first","last","gender","street","city","state","zip","lat","long","city_pop","job","dob","trans_num","unix_time","merch_lat","merch_long","is_fraud"]
#	remove_field => ["host", "@timestamp", "@version", "message","path"]
	}

	date {
            match => [ "new_trans_date_trans_time", "yyyy/MM/dd HH:mm:ss" ]				target => "trans_date_trans_time"
		locale => "en"
		timezone => "+00:00"
	}
	
	mutate{
		convert => { "amt" => "float" }
		convert => { "num" => "integer" }
		convert => { "num" => "integer" }
		convert => { "zip" => "integer" }
		convert => { "lat" => "float" }
		convert => { "long" => "float" }
		convert => { "city_pop" => "integer" }
		convert => { "unix_time" => "integer" }
		convert => { "merch_lat" => "float" }
		convert => { "merch_long" => "float" }
		convert => { "is_fraud" => "integer" }
	}



	mutate {
        add_field => ["[location]", "%{long}"]
        add_field => ["[location]", "%{lat}"]
        }

        mutate{
        convert  => ["[location]","float"]
                        }


	mutate {
        add_field => ["[merch_location]", "%{merch_long}"]
        add_field => ["[merch_location]", "%{merch_lat}"]
        }

        mutate{
        convert  => ["[merch_location]","float"]
                        }


}

output {
  elasticsearch {
    hosts => ["http://es.guled.net:9202"]
    index => "fraudtrain3"
    template => "./fraudtrain.json"
    template_name => "fraud"
    template_overwrite => true
    user => "elastic"
    password => "guled1113"
  }

stdout{}

}
